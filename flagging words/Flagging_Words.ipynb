{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Mq5r6y_sLMEF"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "#import the phrase matcher\n",
        "from spacy.matcher import PhraseMatcher"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load a model and create nlp object\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "syT4BTEmLfMp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initilize the matcher with a shared vocab\n",
        "matcher = PhraseMatcher(nlp.vocab)"
      ],
      "metadata": {
        "id": "IQhL__3qLrdR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create the list of words to match\n",
        "phrases = ['whatever','hate','nervous']"
      ],
      "metadata": {
        "id": "RDg9DOrULude"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patterns = [nlp(text) for text in phrases]"
      ],
      "metadata": {
        "id": "WHRFHi8CMP87"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#you need to add your phrase list to the phrase matcher.\n",
        "matcher.add('AI', None, *patterns)"
      ],
      "metadata": {
        "id": "A7qGXvf0Mdqh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc=open('/content/answer.txt','r')\n",
        "with open('/content/answer.txt') as f:\n",
        "    # contents = f.readlines()\n",
        "    contents=f.read().rstrip()\n",
        "print(contents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3vmNbGTNKO3",
        "outputId": "9b339c7f-552d-4b4d-86cf-b70119ad809b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sure, so, my name is Joe and I am 27 years old. For the past 5 years, I’ve been working as a business analyst at Company X and Y. I have some background in data analysis, with a degree from University XY. What really got me into the field, though, is the internship I did at Company Z. Throughout my career, I’ve noticed that I’ve always been good with numbers and handling data. For example, when I was working at Company X, I led a project for migrating all operations data to a new data warehousing system to cut down on costs. The new solution was a much better fit for our business, which eventually led to savings of up to $200,000 annually. One quality I don’t like about myself is I get nervous too easily but whatever it happens with everyone I think.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Remove stopwords"
      ],
      "metadata": {
        "id": "w2abmtpkSaR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "    \n",
        "stop_words = set(stopwords.words('english'))\n",
        "  \n",
        "word_tokens = word_tokenize(contents)\n",
        "  \n",
        "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "  \n",
        "filtered_sentence = []\n",
        "  \n",
        "for w in word_tokens:\n",
        "    if w not in stop_words:\n",
        "        filtered_sentence.append(w)\n",
        "  \n",
        "print(word_tokens)\n",
        "print(filtered_sentence)\n",
        "   \n",
        "# Function to convert \n",
        "def listToString(s):\n",
        "   \n",
        "    # initialize an empty string\n",
        "    str1 = \" \"\n",
        "   \n",
        "    # return string \n",
        "    return (str1.join(s))\n",
        "       \n",
        "# Driver code\n",
        "\n",
        "filtered_sentence= listToString(filtered_sentence)\n",
        "print(filtered_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KENG2Xd-UGA0",
        "outputId": "1641cf30-8bad-41c6-9a5c-3e34db55032c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sure', ',', 'so', ',', 'my', 'name', 'is', 'Joe', 'and', 'I', 'am', '27', 'years', 'old', '.', 'For', 'the', 'past', '5', 'years', ',', 'I', '’', 've', 'been', 'working', 'as', 'a', 'business', 'analyst', 'at', 'Company', 'X', 'and', 'Y.', 'I', 'have', 'some', 'background', 'in', 'data', 'analysis', ',', 'with', 'a', 'degree', 'from', 'University', 'XY', '.', 'What', 'really', 'got', 'me', 'into', 'the', 'field', ',', 'though', ',', 'is', 'the', 'internship', 'I', 'did', 'at', 'Company', 'Z', '.', 'Throughout', 'my', 'career', ',', 'I', '’', 've', 'noticed', 'that', 'I', '’', 've', 'always', 'been', 'good', 'with', 'numbers', 'and', 'handling', 'data', '.', 'For', 'example', ',', 'when', 'I', 'was', 'working', 'at', 'Company', 'X', ',', 'I', 'led', 'a', 'project', 'for', 'migrating', 'all', 'operations', 'data', 'to', 'a', 'new', 'data', 'warehousing', 'system', 'to', 'cut', 'down', 'on', 'costs', '.', 'The', 'new', 'solution', 'was', 'a', 'much', 'better', 'fit', 'for', 'our', 'business', ',', 'which', 'eventually', 'led', 'to', 'savings', 'of', 'up', 'to', '$', '200,000', 'annually', '.', 'One', 'quality', 'I', 'don', '’', 't', 'like', 'about', 'myself', 'is', 'I', 'get', 'nervous', 'too', 'easily', 'but', 'whatever', 'it', 'happens', 'with', 'everyone', 'I', 'think', '.']\n",
            "['sure', ',', ',', 'name', 'Joe', 'I', '27', 'years', 'old', '.', 'For', 'past', '5', 'years', ',', 'I', '’', 'working', 'business', 'analyst', 'Company', 'X', 'Y.', 'I', 'background', 'data', 'analysis', ',', 'degree', 'University', 'XY', '.', 'What', 'really', 'got', 'field', ',', 'though', ',', 'internship', 'I', 'Company', 'Z', '.', 'Throughout', 'career', ',', 'I', '’', 'noticed', 'I', '’', 'always', 'good', 'numbers', 'handling', 'data', '.', 'For', 'example', ',', 'I', 'working', 'Company', 'X', ',', 'I', 'led', 'project', 'migrating', 'operations', 'data', 'new', 'data', 'warehousing', 'system', 'cut', 'costs', '.', 'The', 'new', 'solution', 'much', 'better', 'fit', 'business', ',', 'eventually', 'led', 'savings', '$', '200,000', 'annually', '.', 'One', 'quality', 'I', '’', 'like', 'I', 'get', 'nervous', 'easily', 'whatever', 'happens', 'everyone', 'I', 'think', '.']\n",
            "sure , , name Joe I 27 years old . For past 5 years , I ’ working business analyst Company X Y. I background data analysis , degree University XY . What really got field , though , internship I Company Z . Throughout career , I ’ noticed I ’ always good numbers handling data . For example , I working Company X , I led project migrating operations data new data warehousing system cut costs . The new solution much better fit business , eventually led savings $ 200,000 annually . One quality I ’ like I get nervous easily whatever happens everyone I think .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Remove Punctutation"
      ],
      "metadata": {
        "id": "M7UWVMvsZv1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "final = filtered_sentence.translate(str.maketrans('', '', string.punctuation))\n",
        "print(final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ogtp7UiJYnLa",
        "outputId": "900c4b61-799c-4d52-a480-01608b631d7c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sure   name Joe I 27 years old  For past 5 years  I ’ working business analyst Company X Y I background data analysis  degree University XY  What really got field  though  internship I Company Z  Throughout career  I ’ noticed I ’ always good numbers handling data  For example  I working Company X  I led project migrating operations data new data warehousing system cut costs  The new solution much better fit business  eventually led savings  200000 annually  One quality I ’ like I get nervous easily whatever happens everyone I think \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = nlp(final)\n",
        "matches = matcher(sentence)"
      ],
      "metadata": {
        "id": "oQg5UrE_Q3qF"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Words you are not suppose to use:- \\n\")\n",
        "for match_id, start, end in matches:\n",
        "    span = sentence[start:end]\n",
        "    print(span.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIHQxr8TRijn",
        "outputId": "9faf78fa-3342-4a5d-9b7d-0b200f3450e1"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words you are not suppose to use:- \n",
            "\n",
            "nervous\n",
            "whatever\n"
          ]
        }
      ]
    }
  ]
}